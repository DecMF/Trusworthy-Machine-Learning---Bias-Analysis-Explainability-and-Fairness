{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, brier_score_loss, log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\decmg\\OneDrive\\Documentos\\Material Disciplinas\\MO436-IA Ética\\Atividade 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def statistical_parity_difference(data, sensitive_attr, predicted_label, positive_class=1):\n",
    "    \"\"\"\n",
    "    Calcula a Statistical Parity Difference (SPD).\n",
    "    \"\"\"\n",
    "    groups = data[sensitive_attr].unique()\n",
    "    priv_group = groups[0]  # Grupo privilegiado\n",
    "    unpriv_group = groups[1]  # Grupo não-privilegiado\n",
    "    \n",
    "    prob_priv = data[data[sensitive_attr] == priv_group][predicted_label].mean()\n",
    "    prob_unpriv = data[data[sensitive_attr] == unpriv_group][predicted_label].mean()\n",
    "    \n",
    "    spd = prob_unpriv - prob_priv\n",
    "    return spd\n",
    "\n",
    "def disparate_impact(data, sensitive_attr, predicted_label, positive_class=1):\n",
    "    \"\"\"\n",
    "    Calcula o Disparate Impact (DI).\n",
    "    \"\"\"\n",
    "    groups = data[sensitive_attr].unique()\n",
    "    priv_group = groups[0]  # Grupo privilegiado\n",
    "    unpriv_group = groups[1]  # Grupo não-privilegiado\n",
    "    \n",
    "    prob_priv = data[data[sensitive_attr] == priv_group][predicted_label].mean()\n",
    "    prob_unpriv = data[data[sensitive_attr] == unpriv_group][predicted_label].mean()\n",
    "    \n",
    "    di = prob_unpriv / prob_priv if prob_priv != 0 else 0\n",
    "    return di\n",
    "\n",
    "def average_odds_difference(data, sensitive_attr, actual_label, predicted_label, positive_class=1):\n",
    "    \"\"\"\n",
    "    Calcula a Average Odds Difference (AOD).\n",
    "    \"\"\"\n",
    "    groups = data[sensitive_attr].unique()\n",
    "    priv_group = groups[0]\n",
    "    unpriv_group = groups[1]\n",
    "    \n",
    "    # Verdadeiros positivos rate\n",
    "    tpr_priv = data[(data[sensitive_attr] == priv_group) & (data[actual_label] == positive_class)][predicted_label].mean()\n",
    "    tpr_unpriv = data[(data[sensitive_attr] == unpriv_group) & (data[actual_label] == positive_class)][predicted_label].mean()\n",
    "    \n",
    "    # Verdadeiros negativos rate\n",
    "    fpr_priv = data[(data[sensitive_attr] == priv_group) & (data[actual_label] != positive_class)][predicted_label].mean()\n",
    "    fpr_unpriv = data[(data[sensitive_attr] == unpriv_group) & (data[actual_label] != positive_class)][predicted_label].mean()\n",
    "    \n",
    "    aod = 0.5 * ((tpr_unpriv - tpr_priv) + (fpr_unpriv - fpr_priv))\n",
    "    return aod\n",
    "\n",
    "def equalized_odds_difference(data, sensitive_attr, actual_label, predicted_label, positive_class=1):\n",
    "    \"\"\"\n",
    "    Calcula o Equalized Odds Difference (EOD).\n",
    "    \"\"\"\n",
    "    groups = data[sensitive_attr].unique()\n",
    "    priv_group = groups[0]\n",
    "    unpriv_group = groups[1]\n",
    "    \n",
    "    # Verdadeiros positivos rate\n",
    "    tpr_priv = data[(data[sensitive_attr] == priv_group) & (data[actual_label] == positive_class)][predicted_label].mean()\n",
    "    tpr_unpriv = data[(data[sensitive_attr] == unpriv_group) & (data[actual_label] == positive_class)][predicted_label].mean()\n",
    "    \n",
    "    eod = tpr_unpriv - tpr_priv\n",
    "    return eod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score, log_loss, brier_score_loss, roc_auc_score\n",
    "def calculate_metrics(X_train, X_val, y_train, y_val, models, threshold=0.5):\n",
    "    results = []\n",
    "    predictions = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "        predictions[f\"y_pred_{model_name}\"] = y_pred\n",
    "\n",
    "        metrics = {\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(y_val, y_pred),\n",
    "            \"Recall\": recall_score(y_val, y_pred),\n",
    "            \"Precision\": precision_score(y_val, y_pred),\n",
    "            \"F1 Score\": f1_score(y_val, y_pred),\n",
    "            \"Risk Bayes (Log Loss)\": log_loss(y_val, y_pred_proba) if y_pred_proba is not None else \"N/A\",\n",
    "            \"Brier Score\": brier_score_loss(y_val, y_pred_proba) if y_pred_proba is not None else \"N/A\",\n",
    "            \"AUC\": roc_auc_score(y_val, y_pred_proba) if y_pred_proba is not None else \"N/A\"\n",
    "        }\n",
    "        \n",
    "        results.append(metrics)\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    display(metrics_df)\n",
    "    return metrics_df, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_metrics_multi(df, y_train, sensitive_columns, outcome_column_name, favorable_outcome):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de Statistical Parity, Disparate Impact e Equalized Odds Difference\n",
    "    para múltiplos atributos sensíveis.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (DataFrame): O dataframe contendo os dados (features).\n",
    "    y_train (DataFrame ou Series): O dataframe ou série contendo os targets (rótulos).\n",
    "    sensitive_columns (list): Lista com o nome das colunas sensíveis (ex: ['sex', 'race', 'native_country']).\n",
    "    outcome_column_name (str): O nome que será dado à coluna de resultado binário após combinação com y_train.\n",
    "    favorable_outcome: O valor considerado como resultado favorável (ex: 1 para aprovado).\n",
    "\n",
    "    Retorna:\n",
    "    DataFrame: Um dataframe contendo as métricas de Statistical Parity, Disparate Impact e EOD.\n",
    "    \"\"\"\n",
    "    df_combined = df.copy()\n",
    "    df_combined[outcome_column_name] = y_train  # Adiciona a coluna target ao DataFrame\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for col in sensitive_columns:\n",
    "        group_favorable_rate = df_combined.groupby(col).apply(\n",
    "            lambda x: (x[outcome_column_name] == favorable_outcome).mean()\n",
    "        ).reset_index(name='Favorable Rate')\n",
    "\n",
    "        protected_rate = group_favorable_rate.loc[group_favorable_rate[col] == 1, 'Favorable Rate'].values[0]\n",
    "        non_protected_rate = group_favorable_rate.loc[group_favorable_rate[col] == 0, 'Favorable Rate'].values[0]\n",
    "\n",
    "        parity_diff = abs(protected_rate - non_protected_rate)\n",
    "\n",
    "        disparate_impact = protected_rate / non_protected_rate if non_protected_rate > 0 else 0\n",
    "\n",
    "        protected_true_positive_rate = df_combined[\n",
    "            (df_combined[col] == 1) & (df_combined[outcome_column_name] == favorable_outcome)\n",
    "        ].shape[0] / df_combined[df_combined[col] == 1].shape[0]\n",
    "\n",
    "        non_protected_true_positive_rate = df_combined[\n",
    "            (df_combined[col] == 0) & (df_combined[outcome_column_name] == favorable_outcome)\n",
    "        ].shape[0] / df_combined[df_combined[col] == 0].shape[0]\n",
    "\n",
    "        eod = abs(protected_true_positive_rate - non_protected_true_positive_rate)\n",
    "\n",
    "        results.append({\n",
    "            'Sensitive Attribute': col,\n",
    "            'Protected Group': 1,\n",
    "            'Non-Protected Group': 0,\n",
    "            'Protected Favorable Rate': protected_rate,\n",
    "            'Non-Protected Favorable Rate': non_protected_rate,\n",
    "            'Statistical Parity': parity_diff,\n",
    "            'Disparate Impact': disparate_impact,\n",
    "            'Equalized Odds Difference (EOD)': eod\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = pd.read_csv('X_train.csv'),pd.read_csv('X_val.csv'),pd.read_csv('y_train.csv'),pd.read_csv('y_val.csv')\n",
    "y_train.drop(['Unnamed: 0'],axis=1,inplace=True),\n",
    "y_val.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "x_train.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "x_val.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imparcialidade antes de Treinar um Modelo (Desconsiderar o EOD nesse caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\decmg\\AppData\\Local\\Temp\\ipykernel_2788\\1529215269.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_favorable_rate = df_combined.groupby(col).apply(\n",
      "C:\\Users\\decmg\\AppData\\Local\\Temp\\ipykernel_2788\\1529215269.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_favorable_rate = df_combined.groupby(col).apply(\n",
      "C:\\Users\\decmg\\AppData\\Local\\Temp\\ipykernel_2788\\1529215269.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_favorable_rate = df_combined.groupby(col).apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitive Attribute</th>\n",
       "      <th>Protected Group</th>\n",
       "      <th>Non-Protected Group</th>\n",
       "      <th>Protected Favorable Rate</th>\n",
       "      <th>Non-Protected Favorable Rate</th>\n",
       "      <th>Statistical Parity</th>\n",
       "      <th>Disparate Impact</th>\n",
       "      <th>Equalized Odds Difference (EOD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.313690</td>\n",
       "      <td>0.199504</td>\n",
       "      <td>0.364009</td>\n",
       "      <td>0.199504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>race</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158850</td>\n",
       "      <td>0.263659</td>\n",
       "      <td>0.104809</td>\n",
       "      <td>0.602482</td>\n",
       "      <td>0.104809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>native_country</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195528</td>\n",
       "      <td>0.254239</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.769073</td>\n",
       "      <td>0.058710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sensitive Attribute  Protected Group  Non-Protected Group  \\\n",
       "0                 sex                1                    0   \n",
       "1                race                1                    0   \n",
       "2      native_country                1                    0   \n",
       "\n",
       "   Protected Favorable Rate  Non-Protected Favorable Rate  Statistical Parity  \\\n",
       "0                  0.114186                      0.313690            0.199504   \n",
       "1                  0.158850                      0.263659            0.104809   \n",
       "2                  0.195528                      0.254239            0.058710   \n",
       "\n",
       "   Disparate Impact  Equalized Odds Difference (EOD)  \n",
       "0          0.364009                         0.199504  \n",
       "1          0.602482                         0.104809  \n",
       "2          0.769073                         0.058710  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_initial = calculate_fairness_metrics_multi(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    sensitive_columns=['sex', 'race', 'native_country'], \n",
    "    outcome_column_name='income', \n",
    "    favorable_outcome=0  # 0 agora é o resultado favorável (alta renda)\n",
    ")\n",
    "result_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar os modelos a serem testados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os modelos já treinados\n",
    "import joblib\n",
    "loaded_models = {}\n",
    "for name in ['rf','nb','knn','SVC','lr']:\n",
    "    loaded_models[name] = joblib.load(f'models//{name}_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tun = loaded_models['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\utils\\optimize.py:99: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    }
   ],
   "source": [
    "lr_tun.fit(x_train, y_train)\n",
    "\n",
    "# Avaliar o modelo no conjunto de validação\n",
    "y_val_pred = lr_tun.predict(x_val)\n",
    "y_val_prob = lr_tun.predict_proba(x_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, ..., 1, 1, 1], dtype=int64),\n",
       " array([0.39608261, 0.58476045, 0.54731181, ..., 0.97724678, 0.87081925,\n",
       "        0.99278732]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred,y_val_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnica de Reghwiehtning - Pre processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.nunique of        income\n",
       "0           1\n",
       "1           1\n",
       "2           0\n",
       "3           0\n",
       "4           0\n",
       "...       ...\n",
       "25632       1\n",
       "25633       0\n",
       "25634       0\n",
       "25635       1\n",
       "25636       1\n",
       "\n",
       "[25637 rows x 1 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensitive   weights\n",
      "0          0  2.156000\n",
      "1          0  2.156000\n",
      "2          0  4.717019\n",
      "3          0  4.717019\n",
      "4          0  4.717019\n"
     ]
    }
   ],
   "source": [
    "# Garantir que y_train seja unidimensional\n",
    "if isinstance(y_train, pd.DataFrame) or len(y_train.shape) > 1:\n",
    "    y_train = y_train.values.ravel()\n",
    "\n",
    "# Combinar os dados sensíveis e os rótulos em um DataFrame auxiliar\n",
    "temp_df = pd.DataFrame({'sensitive': x_train['sensitive'], 'target': y_train})\n",
    "\n",
    "# Calcular os tamanhos dos grupos (contagem por combinação de valores sensíveis e target)\n",
    "group_counts = temp_df.groupby(['sensitive', 'target']).size()\n",
    "\n",
    "# Calcular os pesos para cada grupo\n",
    "total_count = len(temp_df)\n",
    "group_weights = total_count / (group_counts + 1e-6)\n",
    "\n",
    "# Mapear os pesos de volta para cada linha no DataFrame original\n",
    "x_train['weights'] = temp_df.set_index(['sensitive', 'target']).index.map(group_weights)\n",
    "\n",
    "# Confirmar os primeiros pesos calculados\n",
    "print(x_train[['sensitive', 'weights']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\utils\\optimize.py:99: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with reweighing: 0.7028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_tun.fit(x_train.drop(columns=['sensitive', 'weights']), y_train, sample_weight=x_train['weights'])\n",
    "\n",
    "y_val_pred = lr_tun.predict(x_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Accuracy with reweighing: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_metrics_multi_reweighted(df, y_train, sensitive_columns, outcome_column_name, favorable_outcome, weights_column):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de Statistical Parity, Disparate Impact e Equalized Odds Difference\n",
    "    para múltiplos atributos sensíveis, considerando pesos reweighted.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (DataFrame): O dataframe contendo os dados (features).\n",
    "    y_train (DataFrame ou Series): O dataframe ou série contendo os targets (rótulos).\n",
    "    sensitive_columns (list): Lista com o nome das colunas sensíveis (ex: ['sex', 'race', 'native_country']).\n",
    "    outcome_column_name (str): O nome que será dado à coluna de resultado binário após combinação com y_train.\n",
    "    favorable_outcome: O valor considerado como resultado favorável (ex: 1 para aprovado).\n",
    "    weights_column (str): O nome da coluna que contém os pesos reweighted.\n",
    "\n",
    "    Retorna:\n",
    "    DataFrame: Um dataframe contendo as métricas de fairness considerando reweighting.\n",
    "    \"\"\"\n",
    "    df_combined = df.copy()\n",
    "    df_combined[outcome_column_name] = y_train  \n",
    "    results = []\n",
    "    \n",
    "    for col in sensitive_columns:\n",
    "        # Calcular a taxa de resultado favorável ponderada para cada grupo\n",
    "        group_favorable_rate = df_combined.groupby(col).apply(\n",
    "            lambda x: np.sum((x[outcome_column_name] == favorable_outcome) * x[weights_column]) /\n",
    "                      np.sum(x[weights_column])\n",
    "        ).reset_index(name='Favorable Rate')\n",
    "        protected_rate = group_favorable_rate.loc[group_favorable_rate[col] == 1, 'Favorable Rate'].values[0]\n",
    "        non_protected_rate = group_favorable_rate.loc[group_favorable_rate[col] == 0, 'Favorable Rate'].values[0]\n",
    "\n",
    "        parity_diff = abs(protected_rate - non_protected_rate)\n",
    "\n",
    "        disparate_impact = protected_rate / non_protected_rate if non_protected_rate > 0 else 0\n",
    "\n",
    "        protected_true_positive_rate = np.sum(\n",
    "            (df_combined[col] == 1) & (df_combined[outcome_column_name] == favorable_outcome) *\n",
    "            df_combined[weights_column]\n",
    "        ) / np.sum((df_combined[col] == 1) * df_combined[weights_column])\n",
    "\n",
    "        non_protected_true_positive_rate = np.sum(\n",
    "            (df_combined[col] == 0) & (df_combined[outcome_column_name] == favorable_outcome) *\n",
    "            df_combined[weights_column]\n",
    "        ) / np.sum((df_combined[col] == 0) * df_combined[weights_column])\n",
    "\n",
    "        eod = abs(protected_true_positive_rate - non_protected_true_positive_rate)\n",
    "\n",
    "        results.append({\n",
    "            'Sensitive Attribute': col,\n",
    "            'Protected Group': 1,\n",
    "            'Non-Protected Group': 0,\n",
    "            'Protected Favorable Rate': protected_rate,\n",
    "            'Non-Protected Favorable Rate': non_protected_rate,\n",
    "            'Statistical Parity': parity_diff,\n",
    "            'Disparate Impact': disparate_impact,\n",
    "            'Equalized Odds Difference (EOD)': eod\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sensitive Attribute  Protected Group  Non-Protected Group  \\\n",
      "0           sensitive                1                    0   \n",
      "\n",
      "   Protected Favorable Rate  Non-Protected Favorable Rate  Statistical Parity  \\\n",
      "0                       0.5                           0.5        2.045033e-10   \n",
      "\n",
      "   Disparate Impact  Equalized Odds Difference (EOD)  \n",
      "0               1.0                         0.088329  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\decmg\\AppData\\Local\\Temp\\ipykernel_11296\\2977803634.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_favorable_rate = df_combined.groupby(col).apply(\n"
     ]
    }
   ],
   "source": [
    "x_train['weights'] = x_train['weights'] \n",
    "\n",
    "fairness_metrics_reweighted = calculate_fairness_metrics_multi_reweighted(\n",
    "    df=x_train,\n",
    "    y_train=y_train,\n",
    "    sensitive_columns=['sensitive'],\n",
    "    outcome_column_name='predicted',\n",
    "    favorable_outcome=1,  \n",
    "    weights_column='weights'\n",
    ")\n",
    "\n",
    "print(fairness_metrics_reweighted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodologia In-Processing Fairness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def fairness_penalty(predictions, sensitive_column, favorable_outcome):\n",
    "    \"\"\"\n",
    "    Calcula a penalidade de fairness com base na Demographic Parity.\n",
    "    Penalidade é proporcional à diferença entre as taxas de resultado favorável dos grupos.\n",
    "\n",
    "    predictions: np.array\n",
    "        Predições do modelo (valores binários).\n",
    "    sensitive_column: np.array\n",
    "        Coluna sensível (ex.: sexo, raça).\n",
    "    favorable_outcome: int\n",
    "        Valor considerado como resultado favorável (ex.: 1 para aprovado).\n",
    "    \"\"\"\n",
    "    group_0 = predictions[sensitive_column == 0]\n",
    "    group_1 = predictions[sensitive_column == 1]\n",
    "\n",
    "    rate_0 = np.mean(group_0 == favorable_outcome)\n",
    "    rate_1 = np.mean(group_1 == favorable_outcome)\n",
    "\n",
    "    penalty = abs(rate_0 - rate_1)  \n",
    "    return penalty\n",
    "\n",
    "def train_model_with_fairness_penalty(X_train, y_train, sensitive_column, lr_model, lambda_fairness=1.0):\n",
    "    \"\"\"\n",
    "    Treina um modelo ajustado para fairness, adicionando uma penalidade na loss.\n",
    "\n",
    "    X_train: np.array\n",
    "        Dados de entrada.\n",
    "    y_train: np.array\n",
    "        Rótulos.\n",
    "    sensitive_column: np.array\n",
    "        Coluna sensível (valores 0/1).\n",
    "    lr_model: LogisticRegression\n",
    "        Modelo de regressão logística.\n",
    "    lambda_fairness: float\n",
    "        Peso da penalidade de fairness na loss.\n",
    "    \"\"\"\n",
    "    lr_model.fit(X_train, y_train)  \n",
    "\n",
    "    predictions = lr_model.predict(X_train)\n",
    "\n",
    "\n",
    "    fairness_loss = fairness_penalty(predictions, sensitive_column, favorable_outcome=1)\n",
    "\n",
    "\n",
    "    combined_loss = -lr_model.score(X_train, y_train) + lambda_fairness * fairness_loss\n",
    "\n",
    "    print(f\"Fairness Loss: {fairness_loss:.4f}\")\n",
    "    print(f\"Combined Loss: {combined_loss:.4f}\")\n",
    "\n",
    "    return lr_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sensitive_column = x_train['native_country'].values  # Atributo sensível\n",
    "\n",
    "# Modelo base\n",
    "lr_model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness Loss: 0.0505\n",
      "Combined Loss: -0.7859\n"
     ]
    }
   ],
   "source": [
    "# Treinamento com regularização de fairness\n",
    "trained_model = train_model_with_fairness_penalty(\n",
    "    X_train=x_train,\n",
    "    y_train=y_train,\n",
    "    sensitive_column=sensitive_column,\n",
    "    lr_model=lr_model,\n",
    "    lambda_fairness=0.5  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8097\n",
      "ROC-AUC: 0.8543\n",
      "\n",
      "Fairness Metrics:\n",
      "  Sensitive Attribute  Protected Group  Non-Protected Group  \\\n",
      "0      native_country                1                    0   \n",
      "\n",
      "   Protected Favorable Rate  Non-Protected Favorable Rate  Statistical Parity  \\\n",
      "0                  0.742706                       0.63163            0.111076   \n",
      "\n",
      "   Disparate Impact  Equalized Odds Difference (EOD)  \n",
      "0          1.175856                         0.111076  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\decmg\\AppData\\Local\\Temp\\ipykernel_10984\\1529215269.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_favorable_rate = df_combined.groupby(col).apply(\n"
     ]
    }
   ],
   "source": [
    "# Predições no conjunto de validação\n",
    "\n",
    "# Avaliar fairness\n",
    "fairness_metrics = calculate_fairness_metrics_multi(\n",
    "    df=x_val,\n",
    "    y_train=y_val_pred,\n",
    "    sensitive_columns=['native_country'],\n",
    "    outcome_column_name='predicted',\n",
    "    favorable_outcome=1\n",
    ")\n",
    "\n",
    "# Avaliar performance\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "roc_auc = roc_auc_score(y_val, trained_model.predict_proba(x_val)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"\\nFairness Metrics:\\n{fairness_metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologia Pos-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_metrics_multi_reweighted(df, y_train, sensitive_columns, outcome_column_name, favorable_outcome, weights_column):\n",
    "    \"\"\"\n",
    "    Calcula as métricas de Statistical Parity, Disparate Impact e Equal Opportunity\n",
    "    para múltiplos atributos sensíveis, considerando pesos reweighted.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (DataFrame): O dataframe contendo os dados (features).\n",
    "    y_train (DataFrame ou Series): O dataframe ou série contendo os targets (rótulos).\n",
    "    sensitive_columns (list): Lista com o nome das colunas sensíveis (ex: ['sex', 'race', 'native_country']).\n",
    "    outcome_column_name (str): O nome que será dado à coluna de resultado binário após combinação com y_train.\n",
    "    favorable_outcome: O valor considerado como resultado favorável (ex: 1 para aprovado).\n",
    "    weights_column (str): O nome da coluna que contém os pesos reweighted.\n",
    "\n",
    "    Retorna:\n",
    "    DataFrame: Um dataframe contendo as métricas de fairness considerando reweighting.\n",
    "    \"\"\"\n",
    "    df_combined = df.copy()\n",
    "    df_combined[outcome_column_name] = y_train  # Adiciona a coluna target ao DataFrame\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for col in sensitive_columns:\n",
    "        # Calcular a taxa de resultado favorável ponderada para cada grupo\n",
    "        group_favorable_rate = df_combined.groupby(col).apply(\n",
    "            lambda x: np.sum((x[outcome_column_name] == favorable_outcome) * x[weights_column]) /\n",
    "                      np.sum(x[weights_column])\n",
    "        ).reset_index(name='Favorable Rate')\n",
    "\n",
    "        # Considerar o grupo protegido como aquele cujo valor é 1\n",
    "        protected_rate = group_favorable_rate.loc[group_favorable_rate[col] == 1, 'Favorable Rate'].values[0]\n",
    "        non_protected_rate = group_favorable_rate.loc[group_favorable_rate[col] == 0, 'Favorable Rate'].values[0]\n",
    "\n",
    "        # Calcular o Statistical Parity (diferença nas taxas de resultado favorável ponderadas)\n",
    "        parity_diff = abs(protected_rate - non_protected_rate)\n",
    "\n",
    "        # Calcular o Disparate Impact\n",
    "        disparate_impact = protected_rate / non_protected_rate if non_protected_rate > 0 else 0\n",
    "\n",
    "        # Calcular o Equal Opportunity (diferença nas taxas de verdadeiros positivos ponderadas)\n",
    "        protected_true_positive_rate = np.sum(\n",
    "            (df_combined[col] == 1) & (df_combined[outcome_column_name] == favorable_outcome) &\n",
    "            (y_train == favorable_outcome) * df_combined[weights_column]\n",
    "        ) / np.sum((df_combined[col] == 1) & (y_train == favorable_outcome) * df_combined[weights_column])\n",
    "\n",
    "        non_protected_true_positive_rate = np.sum(\n",
    "            (df_combined[col] == 0) & (df_combined[outcome_column_name] == favorable_outcome) &\n",
    "            (y_train == favorable_outcome) * df_combined[weights_column]\n",
    "        ) / np.sum((df_combined[col] == 0) & (y_train == favorable_outcome) * df_combined[weights_column])\n",
    "\n",
    "        equal_opportunity = abs(protected_true_positive_rate - non_protected_true_positive_rate)\n",
    "\n",
    "        results.append({\n",
    "            'Sensitive Attribute': col,\n",
    "            'Protected Group': 1,\n",
    "            'Non-Protected Group': 0,\n",
    "            'Protected Favorable Rate': protected_rate,\n",
    "            'Non-Protected Favorable Rate': non_protected_rate,\n",
    "            'Statistical Parity': parity_diff,\n",
    "            'Disparate Impact': disparate_impact,\n",
    "            'Equal Opportunity': equal_opportunity\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairlearn\n",
      "  Downloading fairlearn-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from fairlearn) (1.26.3)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from fairlearn) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from fairlearn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from fairlearn) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\decmg\\miniconda3\\envs\\torchgpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
      "Downloading fairlearn-0.11.0-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.3 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 20.5/232.3 kB 682.7 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 153.6/232.3 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.3/232.3 kB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: fairlearn\n",
      "Successfully installed fairlearn-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# Modelo treinado (Logistic Regression)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predições no conjunto de validação\n",
    "y_val_pred = model.predict(x_val)\n",
    "y_val_prob = model.predict_proba(x_val)[:, 1]  # Probabilidades para o rótulo positivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "# Garantir que os dados estão no formato correto\n",
    "if isinstance(y_val, pd.DataFrame) or len(y_val.shape) > 1:\n",
    "    y_val = y_val.values.ravel()\n",
    "\n",
    "if isinstance(x_val['race'], pd.DataFrame) or len(x_val['race'].shape) > 1:\n",
    "    sensitive_features = x_val['race'].values.ravel()\n",
    "else:\n",
    "    sensitive_features = x_val['race']\n",
    "\n",
    "# Configurar e ajustar com Equalized Odds\n",
    "threshold_optimizer = ThresholdOptimizer(\n",
    "    estimator=model,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\"\n",
    ")\n",
    "\n",
    "# Ajustar as predições no conjunto de validação\n",
    "threshold_optimizer.fit(x_val, y_val, sensitive_features=sensitive_features)\n",
    "\n",
    "# Fazer predições ajustadas\n",
    "y_val_adjusted = threshold_optimizer.predict(x_val, sensitive_features=sensitive_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = x_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Model Accuracy: 0.8309\n",
      "Adjusted Model ROC-AUC: 0.6899\n",
      "\n",
      "Fairness Metrics After Post-Processing:\n",
      "  Sensitive Attribute  Protected Group  Non-Protected Group  \\\n",
      "0                race                1                    0   \n",
      "\n",
      "   Protected Favorable Rate  Non-Protected Favorable Rate  Statistical Parity  \\\n",
      "0                  0.890263                      0.843218            0.047045   \n",
      "\n",
      "   Disparate Impact  Equalized Odds Difference (EOD)  \n",
      "0          1.055792                         0.047045  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decmg\\miniconda3\\envs\\torchgpu\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\decmg\\AppData\\Local\\Temp\\ipykernel_2788\\1529215269.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_favorable_rate = df_combined.groupby(col).apply(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "# Garantir que y_val seja 1D\n",
    "if len(y_val.shape) > 1:\n",
    "    y_val = y_val[:, 0]  # Selecionar apenas a primeira coluna, se necessário\n",
    "\n",
    "# Garantir que sensitive_features esteja no formato correto\n",
    "if isinstance(x_val['race'], pd.DataFrame) or len(x_val['race'].shape) > 1:\n",
    "    sensitive_features = x_val['race'].values.ravel()\n",
    "else:\n",
    "    sensitive_features = x_val['race']\n",
    "\n",
    "# Configurar o Equalized Odds Threshold Optimizer\n",
    "threshold_optimizer = ThresholdOptimizer(\n",
    "    estimator=model,  # Modelo original treinado\n",
    "    constraints=\"equalized_odds\",  # Garantir Equalized Odds\n",
    "    predict_method=\"predict_proba\"  # Usar probabilidades para ajuste\n",
    ")\n",
    "\n",
    "# Ajustar o modelo usando os dados de validação\n",
    "threshold_optimizer.fit(X_val_scaled, y_val, sensitive_features=sensitive_features)\n",
    "\n",
    "# Fazer predições ajustadas (classe ajustada)\n",
    "y_val_adjusted = threshold_optimizer.predict(X_val_scaled, sensitive_features=sensitive_features)\n",
    "\n",
    "# Fazer predições ajustadas de probabilidades\n",
    "y_val_prob_adjusted = threshold_optimizer._pmf_predict(\n",
    "    X_val_scaled, sensitive_features=sensitive_features\n",
    ")\n",
    "\n",
    "# Garantir que y_val_prob_adjusted seja um array 1D (somente as probabilidades da classe positiva)\n",
    "if y_val_prob_adjusted.ndim > 1:\n",
    "    y_val_prob_adjusted = y_val_prob_adjusted[:, 1]  # Selecionar a coluna da classe positiva\n",
    "\n",
    "# Avaliar métricas de fairness usando as predições ajustadas\n",
    "fairness_metrics_adjusted = calculate_fairness_metrics_multi(\n",
    "    df=x_val,\n",
    "    y_train=y_val_adjusted,  # Previsões ajustadas\n",
    "    sensitive_columns=['race'],  # Atributo sensível\n",
    "    outcome_column_name='adjusted_predicted',  # Nome para as predições ajustadas\n",
    "    favorable_outcome=1\n",
    ")\n",
    "\n",
    "# Avaliar métricas de performance\n",
    "accuracy_adjusted = accuracy_score(y_val, y_val_adjusted)\n",
    "roc_auc_adjusted = roc_auc_score(y_val, y_val_prob_adjusted)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Adjusted Model Accuracy: {accuracy_adjusted:.4f}\")\n",
    "print(f\"Adjusted Model ROC-AUC: {roc_auc_adjusted:.4f}\")\n",
    "print(\"\\nFairness Metrics After Post-Processing:\")\n",
    "print(fairness_metrics_adjusted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
